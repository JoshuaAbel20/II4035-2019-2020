{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # hanya diperlukan untuk disable GPU\n",
    "\n",
    "import tensorflow as tf  \n",
    "import tensorflow.keras as keras  # pakai Keras dari tensorflow\n",
    "import os  \n",
    "from tensorflow.keras.layers import Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D  \n",
    "from tensorflow.keras.models import Model  \n",
    "from tensorflow.keras.optimizers import RMSprop, SGD  \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  \n",
    "from tensorflow.keras.callbacks import EarlyStopping  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  \n",
    "from tensorflow.keras.callbacks import CSVLogger  \n",
    "from tensorflow.keras.layers import BatchNormalization  \n",
    "from tensorflow.keras.models import load_model  \n",
    "import numpy as np  \n",
    "from pathlib import Path  \n",
    "import shutil  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU') # daftar GPU tersedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('CPU') # daftar CPU tersedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow version: \"+tf.__version__) # cek versi Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #making training & validation directories  \n",
    " import pathlib  \n",
    " session='sesi-01'  \n",
    " classnames=['Black-grass','Charlock','Cleavers','Common Chickweed','Common wheat','Fat Hen','Loose Silky-bent','Maize','Scentless Mayweed','Shepherds Purse','Small-flowered Cranesbill','Sugar beet']  \n",
    " train_dir=session+\"/train\"  \n",
    " valid_dir=session+\"/valid\"  \n",
    " for dirname in classnames:  \n",
    " #  print(dirname)  \n",
    "   fulldirname=train_dir+'/'+dirname    \n",
    "   print(fulldirname)  \n",
    "   pathlib.Path(fulldirname).mkdir(parents=True, exist_ok=True)  \n",
    "   fulldirname=valid_dir+'/'+dirname    \n",
    "   print(fulldirname)  \n",
    "   pathlib.Path(fulldirname).mkdir(parents=True, exist_ok=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy image files, split 80% training- 20% validation  \n",
    "\n",
    "original_data_dir=\"original-image/plant-seedlings-classification/train\"\n",
    "\n",
    "counter=0  \n",
    "for root, dirs, files in os.walk(original_data_dir): \n",
    "    print(root)\n",
    "    for file in files:  \n",
    "        fullfilename = os.path.join(root, file)        \n",
    "        basename=os.path.basename(fullfilename)  \n",
    "       #detect image classification from directory name  \n",
    "        split1=os.path.split(fullfilename)        \n",
    "        split2=os.path.split(split1[0])  \n",
    "        classname=str(split2[1])#classname for this particular file  \n",
    "        if((counter%5)==0): #copy validation  \n",
    "            dst_filename=valid_dir+\"/\"+classname+\"/\"+basename  \n",
    "            print(\"copy \"+fullfilename+\" -> \"+dst_filename)\n",
    "            shutil.copyfile(fullfilename,dst_filename)      \n",
    "        else:       #copy training    \n",
    "            dst_filename=train_dir+\"/\"+classname+\"/\"+basename  \n",
    "            shutil.copyfile(fullfilename,dst_filename)      \n",
    "        counter=counter+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare model    \n",
    "img_width=224\n",
    "img_height=224\n",
    "\n",
    "cnn_notop=keras.applications.nasnet.NASNetMobile(input_shape=(img_width, img_height, 3)\n",
    "                                                 , include_top=False\n",
    "                                                 , weights='imagenet' # menggunakan transfer learning\n",
    "#                                                 , weights=None # tanpa transfer learning\n",
    "                                                 , input_tensor=None\n",
    "                                                 , pooling=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cnn_notop.output  \n",
    "x = GlobalAveragePooling2D()(x)      \n",
    "x = Dense(1024, activation='relu')(x)      \n",
    "x = BatchNormalization()(x)  \n",
    "predictions = Dense(12, activation='softmax')(x)  \n",
    "the_model = Model(cnn_notop.input, predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training  \n",
    "learning_rate = 0.0001   \n",
    "logfile = session + '-train' + '.log'   \n",
    "batch_size=32\n",
    "nbr_epochs=100\n",
    "print(\"training  directory: \"+train_dir)  \n",
    "print(\"valication directory: \"+valid_dir)  \n",
    "optimizer = SGD(lr=learning_rate, momentum=0.9, decay=0.0, nesterov=True)  \n",
    "the_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])  \n",
    "csv_logger = CSVLogger(logfile, append=True)  \n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')  \n",
    "best_model_filename=session+'-weights.{epoch:02d}-{val_loss:.2f}.h5'   \n",
    "best_model = ModelCheckpoint(best_model_filename, monitor='val_accuracy', verbose=1, save_best_only=True)  \n",
    "  # this is the augmentation configuration we will use for training  \n",
    "train_datagen = ImageDataGenerator(  \n",
    "    rescale=1. / 255,  \n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    rotation_range=90,  \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,  \n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=True)  \n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)  \n",
    "print('prepare train generator')   \n",
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    shuffle=True,  \n",
    "    classes=classnames,  \n",
    "    class_mode='categorical')  \n",
    "print('prepare validation generator')   \n",
    "validation_generator = val_datagen.flow_from_directory(  \n",
    "    valid_dir,  \n",
    "    target_size=(img_width, img_height),  \n",
    "    batch_size=batch_size,  \n",
    "    shuffle=True,  \n",
    "    classes=classnames,  \n",
    "    class_mode='categorical')  \n",
    "print('fit generator')   \n",
    "the_model.fit(  \n",
    "    x=train_generator,  \n",
    "    epochs=nbr_epochs,  \n",
    "    verbose=1,  \n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[best_model, csv_logger, early_stopping]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction   \n",
    "batch_size=4  \n",
    "nbr_test_samples=794    \n",
    "#choose weights file manually   \n",
    "#weights_path = 'simpleNASNet-weights.10-0.17.h5' # choose file manually, filename may be different  \n",
    "#weights_path = 'sesi-01-weights.08-0.58.h5'\n",
    "weights_path = 'sesi-01-weights.07-2.48.h5'\n",
    "test_data_dir = session+'/test/'   \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)   \n",
    "test_generator = test_datagen.flow_from_directory(   \n",
    "    directory=test_data_dir,   \n",
    "    target_size=(img_width, img_height),   \n",
    "    batch_size=batch_size,   \n",
    "    shuffle = False, # no shuffling, since filenames must match predictions. Shuffling may change file sequence   \n",
    "    classes = None, #    \n",
    "    class_mode = None)   \n",
    "test_image_list = test_generator.filenames   \n",
    "print('Loading model and weights')   \n",
    "predict_model = load_model(weights_path)   \n",
    "#predict_model = the_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Begin to predict for testing data ...')   \n",
    "predictions = predict_model.predict(x=test_generator, steps=nbr_test_samples/batch_size,verbose=1)   \n",
    "np.savetxt(session+'-predictions.txt', predictions) # store prediction matrix, for later analysis if necessary   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission  \n",
    "submission_file=session+'-submit.csv'   \n",
    "print('Begin to write submission file:'+submission_file)   \n",
    "f_submit = open(submission_file, 'w')   \n",
    "f_submit.write('file,species\\n')   \n",
    "for i, image_name in enumerate(test_image_list):   \n",
    "  # find maximum prediction of 12  \n",
    "  max_index=0  \n",
    "  max_value=0  \n",
    "  for x in range(0, 12):  \n",
    "    if(predictions[i][x]>max_value):  \n",
    "      max_value=predictions[i][x]  \n",
    "      max_index=x  \n",
    "  basename=os.path.basename(image_name)   \n",
    "  prediction_class = classnames[max_index] # get predictions from array     \n",
    "  f_submit.write('%s,%s\\n' % (basename, prediction_class))   \n",
    "f_submit.close()   \n",
    "print('Finished write submission file ..')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
